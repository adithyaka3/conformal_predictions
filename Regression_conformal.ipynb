{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc02f6cd-c5a6-4ee7-bb26-0ded470d2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target  # Features and target\n",
    "\n",
    "# Shuffle and split data\n",
    "X, y = np.random.permutation(X), np.random.permutation(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff909690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#created the calibration set and the proper training set\n",
    "X_cal = X_train[-500:]\n",
    "y_cal = y_train[-500:]\n",
    "X_proper_train = X_train[:-500]\n",
    "y_proper_train = y_train[:-500]\n",
    "\n",
    "X_proper_train = torch.tensor(X_proper_train, dtype=torch.float32)\n",
    "y_proper_train = torch.tensor(y_proper_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_cal = torch.tensor(X_cal, dtype=torch.float32)\n",
    "y_cal = torch.tensor(y_cal, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c0aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(y_pred, y_true, tau):\n",
    "    errors = y_true - y_pred\n",
    "    return torch.mean(torch.max(tau * errors, (tau - 1) * errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5365e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters: Weight and Bias\n",
    "input_dim = X_proper_train.shape[1]\n",
    "W_lower = torch.randn((input_dim, 1), requires_grad=True, dtype=torch.float32)\n",
    "b_lower = torch.zeros(1, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "W_upper = torch.randn((input_dim, 1), requires_grad=True, dtype=torch.float32)\n",
    "b_upper = torch.zeros(1, requires_grad=True, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.01  # 90% Prediction Interval (5% in each tail)\n",
    "taus = [alpha / 2, 1 - alpha / 2]  # Lower and Upper Quantiles\n",
    "epochs = 500\n",
    "lr = 0.01\n",
    "\n",
    "# Optimizers\n",
    "opt_lower = optim.Adam([W_lower, b_lower], lr=lr)\n",
    "opt_upper = optim.Adam([W_upper, b_upper], lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Lower Quantile Model (tau = alpha/2)\n",
    "    opt_lower.zero_grad()\n",
    "    y_pred_lower = torch.matmul(X_proper_train, W_lower) + b_lower\n",
    "    loss_lower = quantile_loss(y_pred_lower, y_proper_train, taus[0])\n",
    "    loss_lower.backward()\n",
    "    opt_lower.step()\n",
    "\n",
    "    # Upper Quantile Model (tau = 1-alpha/2)\n",
    "    opt_upper.zero_grad()\n",
    "    y_pred_upper = torch.matmul(X_proper_train, W_upper) + b_upper\n",
    "    loss_upper = quantile_loss(y_pred_upper, y_proper_train, taus[1])\n",
    "    loss_upper.backward()\n",
    "    opt_upper.step()\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7852246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91500/2915519900.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_cal = torch.tensor(y_cal)\n"
     ]
    }
   ],
   "source": [
    "y_lower_pred = torch.matmul(X_cal, W_lower).detach().numpy().flatten()\n",
    "y_upper_pred = torch.matmul(X_cal, W_upper).detach().numpy().flatten()\n",
    "\n",
    "y_lower_pred = torch.tensor(y_lower_pred)\n",
    "y_upper_pred = torch.tensor(y_upper_pred)\n",
    "y_cal = torch.tensor(y_cal)\n",
    "\n",
    "score_array = torch.maximum(y_lower_pred - y_cal, y_cal - y_upper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cffcd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the quantile index\n",
    "import math\n",
    "n = score_array.shape[0]\n",
    "quantile_index = math.ceil((n + 1) * (1 - alpha)) / n\n",
    "\n",
    "# Compute the required quantile\n",
    "q_hat = torch.quantile(score_array, quantile_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d343f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91500/2180497115.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_lower_pred_test = torch.matmul(torch.tensor(X_test, dtype=torch.float32), W_lower).detach().numpy().flatten()\n",
      "/tmp/ipykernel_91500/2180497115.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_upper_pred_test = torch.matmul(torch.tensor(X_test, dtype=torch.float32), W_upper).detach().numpy().flatten()\n"
     ]
    }
   ],
   "source": [
    "y_lower_pred_test = torch.matmul(torch.tensor(X_test, dtype=torch.float32), W_lower).detach().numpy().flatten()\n",
    "y_upper_pred_test = torch.matmul(torch.tensor(X_test, dtype=torch.float32), W_upper).detach().numpy().flatten()\n",
    "y_lower_pred_test = torch.tensor(y_lower_pred_test)\n",
    "y_upper_pred_test = torch.tensor(y_upper_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e680a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage Percentage: 52.424198389053345%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "covered = (y_test >= (y_lower_pred_test - q_hat)) & (y_test <= (y_upper_pred_test + q_hat))\n",
    "\n",
    "coverage_percentage = covered.float().mean().item() * 100\n",
    "\n",
    "print(f\"Coverage Percentage: {coverage_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "767f0bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501996007984032"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-alpha + 1 / (n+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
